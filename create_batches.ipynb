{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T07:12:07.776393Z",
     "start_time": "2025-12-03T07:12:07.130503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Take environment variables from .env\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "BATCH_SIZE = 25000\n",
    "\n",
    "with open(\"SpacyProcessing/spacy_unique_ingredients.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    UNIQUE_INGREDIENTS = f.read()\n",
    "\n",
    "with open(\"prompts/system_message_products.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    SYSTEM_MSG_PRODUCTS = f.read()\n",
    "    SYSTEM_MSG_PRODUCTS += UNIQUE_INGREDIENTS\n",
    "\n",
    "# CONFIGURATION\n",
    "INPUT_CSV = \"data/raw/usda_2022_food_branded_experimental_DESCRIPTION_ONLY.csv\"  # Your source file\n",
    "TRACKER_FILE = \"batch_tracker.json\"  # Where we save Batch IDs\n",
    "BATCH_FILE_NAME = \"batch_input.jsonl\"  # The file we will send to OpenAI\n",
    "MODEL_NAME = \"gpt-4o-mini-2024-07-18\"  # this model does not think\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")  # Ensure your env var is set\n",
    "# Initialize Client\n",
    "client = OpenAI(api_key=API_KEY)"
   ],
   "id": "fa415d94dbb5597a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T07:12:10.389611Z",
     "start_time": "2025-12-03T07:12:10.387391Z"
    }
   },
   "cell_type": "code",
   "source": "print(SYSTEM_MSG_PRODUCTS)",
   "id": "d8ab7bdbcac15fec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Role:** Culinary Data Annotator\n",
      "**Task:** Map product names to **one** canonical ingredient label (lowercase string only).\n",
      "\n",
      "# INSTRUCTIONS\n",
      "1.  **Normalize:** Remove brands, quantities, packaging (can, box), marketing (organic, premium), and prep descriptors (sliced, spicy).\n",
      "    * *Keep* identity terms (e.g., *olive oil, taco seasoning, pudding mix*).\n",
      "2.  **Vocabulary:** Use `ALLOWED_INGREDIENTS` as a **priority list**, not a hard limit. If no match fits, output the best real ingredient name.\n",
      "3.  **Heuristics:**\n",
      "    * **Proteins:** Keep meat cuts (*ground beef*) and processed meats (*bacon*). Generalize seafood (*salmon fillet* → *salmon*).\n",
      "    * **Pantry:** Keep explicit types (*tomato paste, olive oil*). Infer context (*soda* → *baking soda*, *coating* → *breadcrumb*).\n",
      "    * **Mixes:** Keep canonical mixes (*cake mix, taco seasoning*).\n",
      "    * **Formatting:** Singularize nouns. Drop \"for/with X\". No dish names.\n",
      "\n",
      "# EXAMPLES\n",
      "kraft shake ’n bake coating for pork → breadcrumb\n",
      "mccormick taco seasoning mix → taco seasoning\n",
      "tempura batter mix → batter mix\n",
      "barilla spaghetti no. 5 → spaghetti\n",
      "la croix lime sparkling water → water\n",
      "arroz con habichuelas colorados → red bean\n",
      "\n",
      "ALLOWED_INGREDIENTS:\n",
      "salt\n",
      "sugar\n",
      "egg\n",
      "onion\n",
      "butter\n",
      "garlic\n",
      "water\n",
      "pepper\n",
      "flour\n",
      "milk\n",
      "olive oil\n",
      "vanilla\n",
      "brown sugar\n",
      "cinnamon\n",
      "tomato\n",
      "soda\n",
      "lemon juice\n",
      "black pepper\n",
      "allpurpose flour\n",
      "margarine\n",
      "carrot\n",
      "cream cheese\n",
      "sour cream\n",
      "celery\n",
      "parsley\n",
      "oil\n",
      "vegetable oil\n",
      "beef\n",
      "vanilla extract\n",
      "green onion\n",
      "parmesan cheese\n",
      "mayonnaise\n",
      "pecan\n",
      "cheddar cheese\n",
      "unsalted butter\n",
      "mushroom\n",
      "cream\n",
      "nutmeg\n",
      "kosher salt\n",
      "vinegar\n",
      "green pepper\n",
      "ginger\n",
      "nut\n",
      "basil\n",
      "honey\n",
      "virgin olive oil\n",
      "potato\n",
      "oregano\n",
      "chicken breast\n",
      "worcestershire\n",
      "thyme\n",
      "soy\n",
      "paprika\n",
      "cornstarch\n",
      "powdered sugar\n",
      "cumin\n",
      "chicken\n",
      "bacon\n",
      "chili\n",
      "pineapple\n",
      "chicken broth\n",
      "walnut\n",
      "granulated sugar\n",
      "shortening\n",
      "red onion\n",
      "freshly black pepper\n",
      "raisin\n",
      "egg yolk\n",
      "cilantro\n",
      "buttermilk\n",
      "lemon\n",
      "rice\n",
      "orange juice\n",
      "red pepper\n",
      "cocoa\n",
      "cheese\n",
      "banana\n",
      "lime juice\n",
      "cayenne pepper\n",
      "strawberry\n",
      "butter margarine\n",
      "apple\n",
      "broccoli\n",
      "cream mushroom soup\n",
      "mozzarella cheese\n",
      "almond\n",
      "juice\n",
      "mustard\n",
      "zucchini\n",
      "whipping cream\n",
      "dijon mustard\n",
      "cream chicken soup\n",
      "cool whip\n",
      "egg white\n",
      "canola oil\n",
      "spinach\n",
      "confectioner\n",
      "tomato paste\n",
      "cube\n",
      "scallion\n",
      "room temperature\n",
      "chocolate chip\n",
      "red bell pepper\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T07:12:12.605707Z",
     "start_time": "2025-12-03T07:12:12.077940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load Data\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "total_rows = len(df)\n",
    "num_batches = ceil(total_rows / BATCH_SIZE)\n",
    "print(f\"Total rows: {total_rows} | Will create {num_batches} batches.\")"
   ],
   "id": "fc6134cd26d735c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Total rows: 1766279 | Will create 71 batches.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T06:57:10.221553Z",
     "start_time": "2025-12-03T06:57:10.215849Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "bacabae5ae3b8166",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   fdc_id                                        description\n",
       "0  167512  Pillsbury Golden Layer Buttermilk Biscuits, Ar...\n",
       "1  167513  Pillsbury, Cinnamon Rolls with Icing, refriger...\n",
       "2  167514  Kraft Foods, Shake N Bake Original Recipe, Coa...\n",
       "3  167515     George Weston Bakeries, Thomas English Muffins\n",
       "4  167516         Waffles, buttermilk, frozen, ready-to-heat"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167512</td>\n",
       "      <td>Pillsbury Golden Layer Buttermilk Biscuits, Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167513</td>\n",
       "      <td>Pillsbury, Cinnamon Rolls with Icing, refriger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167514</td>\n",
       "      <td>Kraft Foods, Shake N Bake Original Recipe, Coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167515</td>\n",
       "      <td>George Weston Bakeries, Thomas English Muffins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167516</td>\n",
       "      <td>Waffles, buttermilk, frozen, ready-to-heat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T06:57:21.981488Z",
     "start_time": "2025-12-03T06:57:17.340637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize tracker list\n",
    "batch_tracking_data = []\n",
    "\n",
    "# 2. Loop through chunks\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * BATCH_SIZE\n",
    "    end_idx = min((i + 1) * BATCH_SIZE, total_rows)\n",
    "\n",
    "    # Get the chunk\n",
    "    df_chunk = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    print(f\"\\nProcessing Batch {i + 1}/{num_batches} (Rows {start_idx} to {end_idx})...\")\n",
    "\n",
    "    # Create JSONL content\n",
    "    jsonl_filename = f\"batch_input_part_{i + 1}.jsonl\"\n",
    "    requests = []\n",
    "\n",
    "    for index, row in df_chunk.iterrows():\n",
    "        req = {\n",
    "            \"custom_id\": str(row['fdc_id']),  # OR fdc_id, whichever is your unique key\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": MODEL_NAME,  # Optimized for cost\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_MSG_PRODUCTS},\n",
    "                    {\"role\": \"user\", \"content\": row['description']}\n",
    "                ],\n",
    "                \"max_tokens\": 10,  # Optimized to stop \"yapping\", use for gpt4 only\n",
    "            }\n",
    "        }\n",
    "        requests.append(req)\n",
    "\n",
    "    # Write JSONL file\n",
    "    with open(jsonl_filename, \"w\") as f:\n",
    "        for req in requests:\n",
    "            f.write(json.dumps(req) + \"\\n\")\n",
    "\n",
    "    # Upload File\n",
    "    print(f\"Uploading {jsonl_filename}...\")\n",
    "    batch_file = client.files.create(\n",
    "        file=open(jsonl_filename, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    # Create Batch Job\n",
    "    print(\"Submitting Batch Job...\")\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "\n",
    "    # Add to tracker\n",
    "    batch_tracking_data.append({\n",
    "        \"batch_index\": i + 1,\n",
    "        \"batch_id\": batch_job.id,\n",
    "        \"status\": \"submitted\",  # Initial status\n",
    "        \"output_csv_name\": f\"results_part_{i + 1}.csv\"\n",
    "    })\n",
    "\n",
    "    print(f\"Batch {i + 1} Submitted! ID: {batch_job.id}\")"
   ],
   "id": "dbb55cc25d912336",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Batch 1/5 (Rows 0 to 1)...\n",
      "Uploading batch_input_part_1.jsonl...\n",
      "Submitting Batch Job...\n",
      "Batch 1 Submitted! ID: batch_692fdf4f6a0c81909a1b95b383372c00\n",
      "\n",
      "Processing Batch 2/5 (Rows 1 to 2)...\n",
      "Uploading batch_input_part_2.jsonl...\n",
      "Submitting Batch Job...\n",
      "Batch 2 Submitted! ID: batch_692fdf504a6881909161d33e1cb8ab1f\n",
      "\n",
      "Processing Batch 3/5 (Rows 2 to 3)...\n",
      "Uploading batch_input_part_3.jsonl...\n",
      "Submitting Batch Job...\n",
      "Batch 3 Submitted! ID: batch_692fdf5103e08190aee3088cf060f486\n",
      "\n",
      "Processing Batch 4/5 (Rows 3 to 4)...\n",
      "Uploading batch_input_part_4.jsonl...\n",
      "Submitting Batch Job...\n",
      "Batch 4 Submitted! ID: batch_692fdf520fd88190b45aa39242401ad4\n",
      "\n",
      "Processing Batch 5/5 (Rows 4 to 5)...\n",
      "Uploading batch_input_part_5.jsonl...\n",
      "Submitting Batch Job...\n",
      "Batch 5 Submitted! ID: batch_692fdf52a6cc819085496e3b3ef98a33\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T07:02:54.379317Z",
     "start_time": "2025-12-03T07:02:54.375936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(TRACKER_FILE, \"w\") as f:\n",
    "    json.dump(batch_tracking_data, f, indent=4)\n",
    "\n",
    "print(f\"\\nAll batches submitted. IDs saved to {TRACKER_FILE}\")"
   ],
   "id": "b53c396febb268fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All batches submitted. IDs saved to batch_tracker.json\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "85ae4c7355e6014b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
