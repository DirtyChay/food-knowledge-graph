{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:39:20.771548Z",
     "start_time": "2025-12-03T15:39:20.093314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Take environment variables from .env\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "start_offset = 25000 * 4 # 4 uploaded successfully\n",
    "\n",
    "BATCH_SIZE = 25000\n",
    "\n",
    "with open(\"SpacyProcessing/spacy_unique_ingredients.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    UNIQUE_INGREDIENTS = f.read()\n",
    "\n",
    "with open(\"prompts/system_message_products.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    SYSTEM_MSG_PRODUCTS = f.read()\n",
    "    SYSTEM_MSG_PRODUCTS += UNIQUE_INGREDIENTS\n",
    "\n",
    "# CONFIGURATION\n",
    "INPUT_CSV = \"data/raw/usda_2022_food_branded_experimental_DESCRIPTION_ONLY.csv\"  # Your source file\n",
    "TRACKER_FILE = \"batch_tracker.json\"  # Where we save Batch IDs\n",
    "BATCH_FILE_NAME = \"batch_input.jsonl\"  # The file we will send to OpenAI\n",
    "MODEL_NAME = \"gpt-4o-mini-2024-07-18\"  # this model does not think\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")  # Ensure your env var is set\n",
    "# Initialize Client\n",
    "client = OpenAI(api_key=API_KEY)"
   ],
   "id": "fa415d94dbb5597a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:39:20.779019Z",
     "start_time": "2025-12-03T15:39:20.776400Z"
    }
   },
   "cell_type": "code",
   "source": "print(SYSTEM_MSG_PRODUCTS)",
   "id": "d8ab7bdbcac15fec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Role:** Culinary Data Annotator\n",
      "**Task:** Map product names to **one** canonical ingredient label (lowercase string only).\n",
      "\n",
      "# INSTRUCTIONS\n",
      "1.  **Normalize:** Remove brands, quantities, packaging (can, box), marketing (organic, premium), and prep descriptors (sliced, spicy).\n",
      "    * *Keep* identity terms (e.g., *olive oil, taco seasoning, pudding mix*).\n",
      "2.  **Vocabulary:** Use `ALLOWED_INGREDIENTS` as a **priority list**, not a hard limit. If no match fits, output the best real ingredient name.\n",
      "3.  **Heuristics:**\n",
      "    * **Proteins:** Keep meat cuts (*ground beef*) and processed meats (*bacon*). Generalize seafood (*salmon fillet* → *salmon*).\n",
      "    * **Pantry:** Keep explicit types (*tomato paste, olive oil*). Infer context (*soda* → *baking soda*, *coating* → *breadcrumb*).\n",
      "    * **Mixes:** Keep canonical mixes (*cake mix, taco seasoning*).\n",
      "    * **Formatting:** Singularize nouns. Drop \"for/with X\". No dish names.\n",
      "\n",
      "# EXAMPLES\n",
      "kraft shake ’n bake coating for pork → breadcrumb\n",
      "mccormick taco seasoning mix → taco seasoning\n",
      "tempura batter mix → batter mix\n",
      "barilla spaghetti no. 5 → spaghetti\n",
      "la croix lime sparkling water → water\n",
      "arroz con habichuelas colorados → red bean\n",
      "\n",
      "ALLOWED_INGREDIENTS:\n",
      "salt\n",
      "sugar\n",
      "egg\n",
      "onion\n",
      "butter\n",
      "garlic\n",
      "water\n",
      "pepper\n",
      "flour\n",
      "milk\n",
      "olive oil\n",
      "vanilla\n",
      "brown sugar\n",
      "cinnamon\n",
      "tomato\n",
      "soda\n",
      "lemon juice\n",
      "black pepper\n",
      "allpurpose flour\n",
      "margarine\n",
      "carrot\n",
      "cream cheese\n",
      "sour cream\n",
      "celery\n",
      "parsley\n",
      "oil\n",
      "vegetable oil\n",
      "beef\n",
      "vanilla extract\n",
      "green onion\n",
      "parmesan cheese\n",
      "mayonnaise\n",
      "pecan\n",
      "cheddar cheese\n",
      "unsalted butter\n",
      "mushroom\n",
      "cream\n",
      "nutmeg\n",
      "kosher salt\n",
      "vinegar\n",
      "green pepper\n",
      "ginger\n",
      "nut\n",
      "basil\n",
      "honey\n",
      "virgin olive oil\n",
      "potato\n",
      "oregano\n",
      "chicken breast\n",
      "worcestershire\n",
      "thyme\n",
      "soy\n",
      "paprika\n",
      "cornstarch\n",
      "powdered sugar\n",
      "cumin\n",
      "chicken\n",
      "bacon\n",
      "chili\n",
      "pineapple\n",
      "chicken broth\n",
      "walnut\n",
      "granulated sugar\n",
      "shortening\n",
      "red onion\n",
      "freshly black pepper\n",
      "raisin\n",
      "egg yolk\n",
      "cilantro\n",
      "buttermilk\n",
      "lemon\n",
      "rice\n",
      "orange juice\n",
      "red pepper\n",
      "cocoa\n",
      "cheese\n",
      "banana\n",
      "lime juice\n",
      "cayenne pepper\n",
      "strawberry\n",
      "butter margarine\n",
      "apple\n",
      "broccoli\n",
      "cream mushroom soup\n",
      "mozzarella cheese\n",
      "almond\n",
      "juice\n",
      "mustard\n",
      "zucchini\n",
      "whipping cream\n",
      "dijon mustard\n",
      "cream chicken soup\n",
      "cool whip\n",
      "egg white\n",
      "canola oil\n",
      "spinach\n",
      "confectioner\n",
      "tomato paste\n",
      "cube\n",
      "scallion\n",
      "room temperature\n",
      "chocolate chip\n",
      "red bell pepper\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:39:21.311874Z",
     "start_time": "2025-12-03T15:39:20.788582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load Data\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(INPUT_CSV, skiprows=range(1, start_offset + 1)).head(50000) # limit from open ai for queued tokens\n",
    "total_rows = len(df)\n",
    "num_batches = ceil(total_rows / BATCH_SIZE)\n",
    "print(f\"Total rows: {total_rows} | Will create {num_batches} batches.\")\n",
    "\n",
    "num_batches=2"
   ],
   "id": "fc6134cd26d735c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Total rows: 50000 | Will create 2 batches.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:39:21.324137Z",
     "start_time": "2025-12-03T15:39:21.318091Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "bacabae5ae3b8166",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   fdc_id                                    description\n",
       "0  371450                              WHOLE WHEAT TOAST\n",
       "1  371451  ANTIUXIXONA, 72% COCOA INTENSE DARK CHOCOLATE\n",
       "2  371452          LINDT, PISTACHIO SWISS MILK CHOCOLATE\n",
       "3  371453                                 CONCON OF MILK\n",
       "4  371454   SOY DOMINICANO, PAPAYA SLICES IN HEAVY SYRUP"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371450</td>\n",
       "      <td>WHOLE WHEAT TOAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>371451</td>\n",
       "      <td>ANTIUXIXONA, 72% COCOA INTENSE DARK CHOCOLATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371452</td>\n",
       "      <td>LINDT, PISTACHIO SWISS MILK CHOCOLATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371453</td>\n",
       "      <td>CONCON OF MILK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371454</td>\n",
       "      <td>SOY DOMINICANO, PAPAYA SLICES IN HEAVY SYRUP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:40:13.904283Z",
     "start_time": "2025-12-03T15:39:21.348361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize tracker list\n",
    "batch_tracking_data = []\n",
    "\n",
    "# 2. Loop through chunks\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * BATCH_SIZE\n",
    "    end_idx = min((i + 1) * BATCH_SIZE, total_rows)\n",
    "\n",
    "    # Get the chunk\n",
    "    df_chunk = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    print(f\"\\nProcessing Batch {i + 1}/{num_batches} (Rows {start_idx} to {end_idx})...\")\n",
    "\n",
    "    # Create JSONL content\n",
    "    jsonl_filename = f\"batch_input_part_{i + 1}.jsonl\"\n",
    "    requests = []\n",
    "\n",
    "    for index, row in df_chunk.iterrows():\n",
    "        req = {\n",
    "            \"custom_id\": str(row['fdc_id']),  # OR fdc_id, whichever is your unique key\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": MODEL_NAME,  # Optimized for cost\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_MSG_PRODUCTS},\n",
    "                    {\"role\": \"user\", \"content\": row['description']}\n",
    "                ],\n",
    "                \"max_tokens\": 10,  # Optimized to stop \"yapping\", use for gpt4 only\n",
    "            }\n",
    "        }\n",
    "        requests.append(req)\n",
    "\n",
    "    # Write JSONL file\n",
    "    with open(jsonl_filename, \"w\") as f:\n",
    "        for req in requests:\n",
    "            f.write(json.dumps(req) + \"\\n\")\n",
    "\n",
    "    # Upload File\n",
    "    print(f\"Uploading {jsonl_filename}...\")\n",
    "    batch_file = client.files.create(\n",
    "        file=open(jsonl_filename, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    # Create Batch Job\n",
    "    print(\"Submitting Batch Job...\")\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "\n",
    "    # Add to tracker\n",
    "    batch_tracking_data.append({\n",
    "        \"batch_index\": i + 1,\n",
    "        \"batch_id\": batch_job.id,\n",
    "        \"status\": \"submitted\",  # Initial status\n",
    "        \"output_csv_name\": f\"results_part_{i + 1}.csv\"\n",
    "    })\n",
    "\n",
    "    print(f\"Batch {i + 1} Submitted! ID: {batch_job.id}\")"
   ],
   "id": "dbb55cc25d912336",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Batch 1/2 (Rows 0 to 25000)...\n",
      "Uploading batch_input_part_1.jsonl...\n",
      "Submitting Batch Job...\n",
      "Batch 1 Submitted! ID: batch_693059c16b0081908e7031a1979caba0\n",
      "\n",
      "Processing Batch 2/2 (Rows 25000 to 50000)...\n",
      "Uploading batch_input_part_2.jsonl...\n",
      "Submitting Batch Job...\n",
      "Batch 2 Submitted! ID: batch_693059ddc5508190a5980e0499136187\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:40:15.042465Z",
     "start_time": "2025-12-03T15:40:15.039616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(TRACKER_FILE, \"w\") as f:\n",
    "    json.dump(batch_tracking_data, f, indent=4)\n",
    "\n",
    "print(f\"\\nAll batches submitted. IDs saved to {TRACKER_FILE}\")"
   ],
   "id": "b53c396febb268fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All batches submitted. IDs saved to batch_tracker.json\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:40:15.061515Z",
     "start_time": "2025-12-03T15:40:15.059712Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "85ae4c7355e6014b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
