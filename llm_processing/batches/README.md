### Batch Processing Code

This folder contains the code required to send and retrieve batch files using the OpenAI API.

Only use these notebooks if you want to reduce cost at the expense of processing time.

Note that these notebook are **not supported** but are included for completeness.

### `create_batches`

This notebook sends batches of rows to OpenAI.  
You may enqueue up to **40 million tokens at a time**, which is roughly **50,000 rows per 24 hours**.  
Batch IDs are stored in `batch_tracker.json`.

### `read_batches`

This notebook retrieves the batches listed in `batch_tracker.json` and aggregates them into a single CSV file.

### `combine_batches_with_single_run`

This notebook combines the output of `read_batches` with the asynchronous LLM output generated by `process_products`.  
